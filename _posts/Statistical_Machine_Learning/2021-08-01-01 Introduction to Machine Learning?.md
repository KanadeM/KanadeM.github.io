---
layout:     post   				    # 使用的布局（不需要改）
title:      Introduction to Maching Learning  	# 标题 
subtitle:   Introduction to Maching Learning  #副标题
date:       2018-02-22			# 时间
author:     Leonard Meng						# 作者
header-img: img/post-banner-ai2.jpg 	#这篇文章标题背景图片
catalog: true 						# 是否归档
mathjax: true                       # 是否启用 MathJax
tags:								#标签
    - Machine Learning
    - AI
---
# 1 什么是机器学习

## 1.1 什么是机器学习

- 对于某给定的任务T，在合理的性能度量方案P的前 提下，某计算机程序可以自主学习任务T的经验E; 随着提供合适、优质、大量的经验E，该程序对于 任务T的性能逐步提高。
- 这里最重要的是机器学习的对象:
  - 任务Task,T，一个或者多个
  - 经验Experience,E
  - 性能Performance,P
- 即:随着任务的不断执行，经验的累积会带来计算 机性能的提升。

简而言之：==机器学习是人工智能的一个分支。我们使用计算机设计一个系统,使它能够根据提供的训练数据按照一定的方式来学习;随着训练次数的增加,该系统可以在性能上不断学习和改进,通过优化该学习模型,能够基于先前学习得到的参数来预测相关问题的输出。==

# 2 分类

从无知到掌握知识，要找到最重要的特征，而不是外形，所以要自学习特征。例如月亮的外形不是最主要特征，夜空中最大最亮的才是月亮的特征。

## 2.1 基本分类

### 2.2.1 监督学习

监督学习( supervised learning)是指从标注数据中学习预测模型的机器学习问题。标注数据表示输入输出的对应关系,预测模型对给定的输入产生相应的输出。==监督学习的本质是学习输入到输出的映射的统计规律==。因为有人工标注的训练数据集，所以称为监督学习。

**输入变量与输出变量均为连续变量的预测问题称为回归问题;输出变量为有限个离散变量的预测问题称为分类问题;输入变量与输出变量均为变量序列的预测问题称为标注问题。**

### 2.2.2 无监督学习

无监督学习( unsupervised learning)是指从无标注数据中学习预测模型的机器学习问题。无标注数据是自然得到的数据,预测模型表示数据的类别、转换或概率。==无监督学习的本质是学习数据中的统计规律或潜在结构。==

### 2.2.3 强化学习

强化学习( reinforcement learning)是指智能系统在与环境的连续互动中学习最优行为策略的机器学习问题。假设智能系统与环境的互动基于马尔可夫决策过程( Markov decision process),智能系统能观測到的是与环境互动得到的数据序列。==强化学习的本质是学习最优的序贯决策==

![image-20210316110142158](../../../../Markdown/image-20210316110142158.png)

### 2.2.4 半监督学习与主动学习

==半监督学习(semi- supervised learning)是指利用标注数据和未标注数据学习预测模型的机器学习问题。==通常有少量标注数据、大量未标注数据,因为标注数据的构建往往需要人工,成本较高,未标注数据的收集不需太多成本。半监督学习旨在利用未标注数据中的信息,辅助标注数据,进行监督学习,以较低的成本达到较好的学习效果

==主动学习( active learning)是指机器不断主动给出实例让教师进行标注,然后利用标注数据学习预测模型的机器学习问题。==通常的监督学习使用给定的标注数据,往往是随机得到的,可以看作是“被动学习”,主动学习的目标是找出对学习最有帮助的实例让教师标注,以较小的标注代价,达到较好的学习效果半监督学习和主动学习更接近监督学习。

## 2.2 按模型分类

### 2.2.1 概率模型与非概率模型

==统计学习的模型可以分为概率模型( probabilistic model)和非概率模型(non probabilistic model)或者确定性模型( deterministic model)。==在监督学习中,概率模型取条件概率分布形式P(y),非概率模型取函数形式y=f(x),其中x是输入,y 是输出。在无监督学习中,概率模型取条件概率分布形式P(z|x)或P(x|z),非概率模型取函数形式z=g(x),其中x是输入,是输出。<font style="color:red;font-weight:bold">在监督学习中,概率模型是生成模型,非概率模型是判别模型。</font>

概率模型：

- 决策树
- 朴素贝叶斯
- 隐马尔可夫模型
- 条件随机场
- 概率潜在语义分析
- 潜在狄利克雷分配
- 高斯混合模型

非概率模型

- 感知机
- 支持向量机
- k近邻
- Adabboost
- k均值
- 潜在语义分析
- 神经网络

==逻辑斯谛回归既可看作是概率模型,又可看作是非概率模型。==

### 2.2.2 线性模型与非线性模型

==统计学习模型,特别是非概率模型,可以分为线性模型( linear model)和非线性模型(non- linear model)。==如果函数y=f(x)或x=g(x)是线性函数,则称模型是线性模型,否则称模型是非线性模型。
线性模型：

- 感知机
- 线性支持向量机
- k近邻
- k均值
- 潜在语义分析

非线性模型

- 核函数支持向量机
- Adaboost
- 神经网络是非线性模型深度学习( deep learning)实际是复杂神经网络的学习,也就是复杂的非线性模型的学习。



### 2.2.3 参数化模型与非参数化模型

统计学习模型又可以分为参数化模型( parametric model)和非参数化模型(non parametric model)。==参数化模型假设模型参数的<font style="color:red">维度固定</font>, 模型可以由有限维参数完全刻画;非参数化模型假设模型参数的<font style="color:red">维度不固定或者说无穷大</font>,随着训练数据量的增加而不断增大

#### 参数化模型

- 感知机
- 朴素贝叶斯
- 逻辑斯谛回归
- k均值
- 高斯混合模型

#### 非参数化模型

- 决策树
- 支持向量机
- Adaboost
- k近邻
- 潜在语义分析
- 概率潜在语义分析
- 潜在狄利克雷分配

## 2.3 按算法分类

### 2.3.1 在线学习

==在线学习是指每次接受一个样本,进行预测,之后学习模型,并不断重复该操作的机器学习。==  <font style="color:red">有些实际应用的场景要求学习必须是在线的。比如,数据依次达到无法存储,系统需要及时处理。或者数据规模太大不能一次处理完。或者数据模式随时间变动需要算法快速适应新的模式</font>

在线学习可以是监督学习,也可以是无监督学习,强化学习本身就拥有在线学习的特点。以下只考虑在线的监督学习。
学习和预测在一个系统,每次接受一个输入t,用已有模型给出预测f(x),之后得到相应的反馈,即该输入对应的输出y+;系统用损失函数计算两者的差异,更新模型;并不断重复以上操作。见图

![image-20210514115045714](../../../../Markdown/image-20210514115045714.png)

利用随机梯度下降的感知机学习算法就是在线学习算法。
在线学习通常比批量学习更难,很难学到预测准确率更高的模型,因为每次模型更新中,可利用的数据有限。

### 2.3.2 批量学习

批量学习一次接受所有数据,学习模型,之后进行预測。

## 2.4 按技巧分类

### 2.4.1 贝叶斯学习

在概率模型的学习和推理中,利用贝叶斯定理,计算在给定数据条件下模型的条件概率,即后验概率,并应用这个原理进行模型的估计,以及对数据的预测。将模型、未观测要素及其参数用变量表示,使用模型的先验分布是贝叶斯学习的特点。

- 朴素贝叶斯

- 潜在狄利克雷分配

### 2.4.2 核方法

==核方法( kernel method)是使用核函数表示和学习非线性模型的一种机器学习方法,可以用于监督学习和无监督学习。==有一些线性模型的学习方法基于相似度计算, 更具体地,向量内积计算。核方法可以把它们扩展到非线性模型的学习,使其应用范围更广泛。

- 支持向量机
- 核K均值

# 3 统计学习方法三要素

## 3.1 模型

==模型的假设空间( hypothesis space)包含所有可能的条件概率分布或决策函数。==

假设空间$\mathcal{F}$可以定义为所有决策函数的集合：
$$
\mathcal{F}=\{f|Y=f(x)\}
$$


所以可以看出假设空间有无穷多个，统计学习的目的就是从假设空间中找到最优模型。

## 3.2 策略

从假设空间中找到模型需要一些指标来评价模型的好坏。

### 3.2.1 损失函数和风险函数

损失函数( loss function)或代价函数( cost function)来度量预测错误的程度。损失函数是f(X)和Y的非负实值函数,记作L(Y,f(X)。

#### 0-1损失函数(0-1 loss function)

$$
L(Y, f(X))= \begin{cases}
   1, & Y\ne f(X)\\
   0, & Y = f(X)
\end{cases}
$$

#### 平方损失函数( quadratic loss function)

$$
L(Y, f(X))= (Y - f(X))^2
$$

#### 绝对损失函数( absolute loss function)

$$
L(Y, f(X))= |Y - f(X)|
$$

#### 对数损失函数( logarithmic loss function)或对数似然损失函数(log- likelihood oss function

$$
L(Y, P(Y|X))=-log P(Y|X)
$$

损失函数值越小,模型就越好。由于模型的输入、输出(X,Y)是随机变量,遵循联合分布P(X,Y),所以损失函数的期望是：
$$
R_{exp}(f)=E_P[L(Y, f(X))] = \int_{\mathcal{X * Y}} L(y, f(x))P(x, y)dxdy
$$
这是理论上模型f(X)关于联合分布P(X,Y)的平均意义下的损失,称为==风险函数( risk function)或期望损失( expected loss)==

### 3.2.2 经验风险最小化与结构风险最小化

==经验风险最小化( empirical risk minimization,ERM)的策略认为,经验风险最小的模型是最优的模型。==

当样本容量足够大时,经验风险最小化能保证有很好的学习效果,在现实中被广泛采用。比如,极大似然估计( maximum likelihood estimation)就是经验风险最小化的一个例子。当模型是条件概率分布、损失函数是对数损失函数时,经验风险最小化就等价于极大似然估计。
但是,当样本容量很小时,经验风险最小化学习的效果就未必很好,会产生==“过拟合”(over- fitting)现象==。

结构风险最小化( structural risk minimization,SRM)是为了防止过拟合而提出来的策略。==结构风险最小化等价于正则化( regularization)。结构风险在经验风险上加上表示模型复杂度的正则化项( regularizer)或罚项( penalty term)。==在假设空间、损失函数以及训练数据集确定的情况下,结构风险的定义是：
$$
R_{srm}(f)= \frac{1}{N}\sum_{i=1}^NL(y_i,f(x_i)+\lambda J(f)
$$
其中$J(f)$为模型的复杂度,是定义在假设空间$\mathcal{F}$上的泛函。模型$f$越复杂,复杂度$J(f)$就越大:反之,模型$f$越简单,复杂度$J(f)$就越小。也就是说,复杂度表示了对复杂模型的惩罚。$\lambda$≥0是系数,用以权衡经验风险和模型复杂度。==结构风险小需要经验风险与模型复杂度同时小。结构风险小的模型往往对训练数据以及未知的测试数据都有较好的预测。==



比如,贝叶斯估计中的最大后验概率估计( maximum posterior probability esti matio,MAP)就是结构风险最小化的一个例子。当模型是条件概率分布、损失函数是对数损失函数、模型复杂度由模型的先验概率表示时,结构风险最小化就等价于最大后验概率估计。
结构风险最小化的策略认为结构风险最小的模型是最优的模型。所以求最优模型,就是求解最优化问题:

这样,监督学习问题就变成了经验风险或结构风险函数的最优化问题(1.15)和(1.17)。这时经验或结构风险函数是最优化的目标函数。



## 3.3 算法

# 4 模型评估与模型选择

## 4.1 训练误差与测试误差

==统计学习的目的是使学到的模型不仅对已知数据而且对未知数据都能有很好的预测能力。==不同的学习方法会给出不同的模型。当损失函数给定时,基于损失函数的模型的训练误差( training error)和模型的测试误差( test error)就自然成为学习方法评估的标准。注意,统计学习方法具体采用的损失函数未必是评估时使用的损失函数。当然,让两者一致是比较理想的。

## 4.2 过拟合与模型选择

当假设空间含有不同复杂度(例如,不同的参数个数)的模型时,就要面临模型选择( model selection)的问题。我们希望选择或学习一个合适的模型。如果在假设空间中存在“真”模型,那么所选择的模型应该逼近真模型。具体地,所选择的模型要与真模型的参数个数相同,所选择的模型的参数向量与真模型的参数向量相近。
==如果一味追求提高对训练数据的预测能力,所选模型的复杂度则往往会比真模型更高。这种现象称为过拟合(over-fitting)==。==过拟合是指学习时选择的模型所包含的参数过多,以至出现这一模型对已知数据预测得很好,但对未知数据预测得很差的现象。可以说模型选择旨在避免过拟合并提高模型的预测能力。==

# 5 正则化与交叉验证

## 5.1 正则化

## 5.2 交叉验证

如果数据充足，将数据集切分为：训练集，验证集和测试机。

针对数据不足的情况，可以将数据进行切分，随机组合为训练集与测试集反复训练。

### 5.2.1 简单交叉验证

简单交叉验证方法是:首先随机地将已给数据分为两部分,一部分作为训练集另一部分作为测试集(例如,70%的数据为训练集,30%的数据为测试集).

### 5.2.2 S折交叉验证

==应用最多==的是S折交又验证(S- fold cross validation),方法如下:首先随机地将已给数据切分为S个互不相交、大小相同的子集:然后利用S-1个子集的数据训练模型,利用余下的子集测试模型;将这一过程对可能的S种选择重复进行;最后选出S次评测中平均测试误差最小的模型。

### 5.2.3 留一交叉验证

S折交叉验证的特殊情形是S=N,称为留一交又验证( leave-one- out cross validation),==往往在数据缺乏的情况下使用==。这里,N是给定数据集的容量

# 6 泛化能力

## 6.1 泛化误差能力

==学习方法的泛化能力( generalization ability)是指由该方法学习到的模型对未知数据的预测能力,==是学习方法本质上重要的性质。现实中采用最多的办法是通过测试误差来评价学习方法的泛化能力。但这种评价是依赖于测试数据集的。因为测试数据集是有限的,很有可能由此得到的评价结果是不可靠的。统计学习理论试图从理论上对学习方法的泛化能力进行分析
$$
R_{exp}(\hat{f})=E_P[L(Y, \hat{f}(X))] = \int_{\mathcal{X * Y}} L(y, \hat{f}(x))P(x, y)dxdy
$$
泛化误差反映了学习方法的泛化能力,如果一种方法学习的模型比另一种方法学习的模型具有更小的泛化误差,那么这种方法就更有效。==事实上,泛化误差就是所学习到的模型的期望风险==

## 6.2 泛化误差上界

==学习方法的泛化能力分析往往是通过研究泛化误差的概率上界进行的==,简称为泛化误差上界( generalization error bound)。

# 7 生成模型与判别模型

生成方法由数据学习联合概率分布P(X,Y),然后求出条件概率分布P(Y|X)作为预测的模型。这样的方法之所以称为生成方法,是因为模型表示了给定输入X产生输出Y的生成关系。典型的生成模型有==朴素贝叶斯法和隐马尔可夫模型,==将在后面章节进行相关讲述。

判別方法由数据直接学习决策函数(X)或者条件概率分布P(Y|X)作为预测的模型,即判别模型。判别方法关心的是对给定的输入X,应该预测什么样的输出Y。
典型的判别模型包括:==k近邻法、感知机、决策树、逻辑斯谛回归模型、最大熵模型、支持向量机、提升方法和条件随机场等==,将在后面章节讲述。

==生成方法的特点:生成方法可以还原出联合概率分布P(X,Y),而判别方法则不能;生成方法的学习收敛速度更快,即当样本容量增加的时候,学到的模型可以更快地收敛于真实模型;当存在隐变量时,仍可以用生成方法学习,此时判别方法就不能用==

==判別方法的特点:判别方法直接学习的是条件概率P(Y|X)或决策函数f(X), 直接面对预测,往往学习的准确率更高;由于直接学习P(Y|X)或f(X),可以对数据进行各种程度上的抽象、定义特征并使用特征,因此可以简化学习问题。==

# 8 监督学习的应用

## 8.1 分类问题

## 8.2 标注问题

## 8.3 回归问题

回归( regression)是监督学习的另一个重要问题。回归用于预测输入变量(自变量)和输出变量(因变量)之间的关系。
